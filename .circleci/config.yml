version: 2
jobs:
  test:
    docker:
      - image: cpdbdev/backend:latest
        user: gunicorn
      - image: cpdbdev/postgres:9.6
      - image: elasticsearch:5-alpine
        name: elasticsearch
      - image: selenium/standalone-chrome:3.11
    environment:
      DJANGO_SETTINGS_MODULE: config.settings.circleci
      DB_HOST: localhost
      DB_USER: cpdb
      DB_PASSWORD: password
      DB_NAME: cpdb
    steps:
      - checkout
      - run: pip install --user -r requirements/test.txt
      - run: flake8
      - run: coverage run cpdb/manage.py test --noinput --nologcapture
      - run: coverage combine
      - run: coverage report --omit="/home/ubuntu/virtualenvs/*"
      - run: coveralls
      - store_artifacts:
          path: /usr/src/app/project/cpdb/test_visual_token_media

  push_backend_image:
    machine: true
    steps:
      - checkout
      - run: echo "build-$CIRCLE_BUILD_NUM" > buildnum
      - persist_to_workspace:
          root: .
          paths:
            - buildnum
      - restore_cache:
          keys:
            - v2-{{ checksum "Dockerfile" }}-{{ checksum "requirements/base.txt" }}-{{ .Branch }}
            - v2-{{ checksum "Dockerfile" }}-{{ checksum "requirements/base.txt" }}
            - v2-{{ checksum "Dockerfile" }}
            - v2
          paths:
            - /caches/app.tar
      - run:
          name: Load Docker image layer cache
          command: |
            set +o pipefail
            docker load -i /caches/app.tar | true
      - run:
          name: Build image
          command: |
            docker build --cache-from=cpdbdev/backend -t cpdbdev/backend:$(cat buildnum) .
            docker build --cache-from=cpdbdev/backend -t cpdbdev/backend .
      - run:
          name: Push image
          command: |
            echo $DOCKER_PASS | docker login -u $DOCKER_USER --password-stdin
            docker push cpdbdev/backend:$(cat buildnum)
      - run:
          name: Save Docker image layer cache
          command: |
            mkdir -p /caches
            docker save -o /caches/app.tar cpdbdev/backend
      - save_cache:
          key: v2-{{ checksum "Dockerfile" }}-{{ checksum "requirements/base.txt" }}-{{ .Branch }}
          paths:
            - /caches/app.tar

  django_collect_static:
    docker:
      - image: cpdbdev/google-cloud-sdk:latest
    environment:
      PROJECT_NAME: "CPDB"
      GOOGLE_PROJECT_ID: "twitterbot-180604"
      GOOGLE_COMPUTE_ZONE: "us-central1-a"
      GOOGLE_CLUSTER_NAME: "cpdp-gke"
    steps:
      - checkout
      - attach_workspace:
          at: /tmp/workspace
      - run:
          name: Setup Google Cloud SDK
          command: |
            echo $GCLOUD_SERVICE_KEY > ${HOME}/gcloud-service-key.json
            gcloud auth activate-service-account --key-file=${HOME}/gcloud-service-key.json
            gcloud --quiet config set project ${GOOGLE_PROJECT_ID}
            gcloud --quiet config set compute/zone ${GOOGLE_COMPUTE_ZONE}
            gcloud --quiet container clusters get-credentials ${GOOGLE_CLUSTER_NAME}
      - run:
          name: Reveal secrets
          command: |
            echo $GPG_PRIVATE_KEY | base64 -d > /tmp/gpg_private.gpg
            gpg --allow-secret-key-import --import /tmp/gpg_private.gpg
            git secret reveal
      - run:
          name: Start job
          command: |
            if [ $CIRCLE_BRANCH == "master" ]
            then
              export ENVFLAG=--production
            else
              export ENVFLAG=--staging
            fi
            bin/run_job.sh $ENVFLAG $(cat /tmp/workspace/buildnum) collectstatic --no-input

  django_migrate:
    docker:
      - image: cpdbdev/google-cloud-sdk:latest
    environment:
      PROJECT_NAME: "CPDB"
      GOOGLE_PROJECT_ID: "twitterbot-180604"
      GOOGLE_COMPUTE_ZONE: "us-central1-a"
      GOOGLE_CLUSTER_NAME: "cpdp-gke"
    steps:
      - checkout
      - attach_workspace:
          at: /tmp/workspace
      - run:
          name: Setup Google Cloud SDK
          command: |
            echo $GCLOUD_SERVICE_KEY > ${HOME}/gcloud-service-key.json
            gcloud auth activate-service-account --key-file=${HOME}/gcloud-service-key.json
            gcloud --quiet config set project ${GOOGLE_PROJECT_ID}
            gcloud --quiet config set compute/zone ${GOOGLE_COMPUTE_ZONE}
            gcloud --quiet container clusters get-credentials ${GOOGLE_CLUSTER_NAME}
      - run:
          name: Reveal secrets
          command: |
            echo $GPG_PRIVATE_KEY | base64 -d > /tmp/gpg_private.gpg
            gpg --allow-secret-key-import --import /tmp/gpg_private.gpg
            git secret reveal
      - run:
          name: Start job
          command: |
            if [ $CIRCLE_BRANCH == "master" ]
            then
              export ENVFLAG=--production
            else
              export ENVFLAG=--staging
            fi
            bin/run_job.sh $ENVFLAG $(cat /tmp/workspace/buildnum) migrate

  rebuild_index:
    docker:
      - image: cpdbdev/google-cloud-sdk:latest
    environment:
      PROJECT_NAME: "CPDB"
      GOOGLE_PROJECT_ID: "twitterbot-180604"
      GOOGLE_COMPUTE_ZONE: "us-central1-a"
      GOOGLE_CLUSTER_NAME: "cpdp-gke"
    steps:
      - checkout
      - attach_workspace:
          at: /tmp/workspace
      - run:
          name: Reveal secrets
          command: |
            echo $GPG_PRIVATE_KEY | base64 -d > /tmp/gpg_private.gpg
            gpg --allow-secret-key-import --import /tmp/gpg_private.gpg
            git secret reveal
      - run:
          name: Setup Google Cloud SDK
          command: |
            echo $GCLOUD_SERVICE_KEY > ${HOME}/gcloud-service-key.json
            gcloud auth activate-service-account --key-file=${HOME}/gcloud-service-key.json
            gcloud --quiet config set project ${GOOGLE_PROJECT_ID}
            gcloud --quiet config set compute/zone ${GOOGLE_COMPUTE_ZONE}
            gcloud --quiet container clusters get-credentials ${GOOGLE_CLUSTER_NAME}
      - run:
          name: Start job
          command: bin/run_job.sh --production $(cat /tmp/workspace/buildnum) rebuild_index

  rebuild_search_index:
    docker:
      - image: cpdbdev/google-cloud-sdk:latest
    environment:
      PROJECT_NAME: "CPDB"
      GOOGLE_PROJECT_ID: "twitterbot-180604"
      GOOGLE_COMPUTE_ZONE: "us-central1-a"
      GOOGLE_CLUSTER_NAME: "cpdp-gke"
    steps:
      - checkout
      - attach_workspace:
          at: /tmp/workspace
      - run:
          name: Reveal secrets
          command: |
            echo $GPG_PRIVATE_KEY | base64 -d > /tmp/gpg_private.gpg
            gpg --allow-secret-key-import --import /tmp/gpg_private.gpg
            git secret reveal
      - run:
          name: Setup Google Cloud SDK
          command: |
            echo $GCLOUD_SERVICE_KEY > ${HOME}/gcloud-service-key.json
            gcloud auth activate-service-account --key-file=${HOME}/gcloud-service-key.json
            gcloud --quiet config set project ${GOOGLE_PROJECT_ID}
            gcloud --quiet config set compute/zone ${GOOGLE_COMPUTE_ZONE}
            gcloud --quiet container clusters get-credentials ${GOOGLE_CLUSTER_NAME}
      - run:
          name: Start job
          command: bin/run_job.sh --production $(cat /tmp/workspace/buildnum) rebuild_search_index

  deploy_backend:
    docker:
      - image: cpdbdev/google-cloud-sdk:latest
    environment:
      PROJECT_NAME: "CPDB"
      GOOGLE_PROJECT_ID: "twitterbot-180604"
      GOOGLE_COMPUTE_ZONE: "us-central1-a"
      GOOGLE_CLUSTER_NAME: "cpdp-gke"
    steps:
      - checkout
      - attach_workspace:
          at: /tmp/workspace
      - run:
          name: Reveal secrets
          command: |
            echo $GPG_PRIVATE_KEY | base64 -d > /tmp/gpg_private.gpg
            gpg --allow-secret-key-import --import /tmp/gpg_private.gpg
            git secret reveal
      - run:
          name: Setup Google Cloud SDK
          command: |
            echo $GCLOUD_SERVICE_KEY > ${HOME}/gcloud-service-key.json
            gcloud auth activate-service-account --key-file=${HOME}/gcloud-service-key.json
            gcloud --quiet config set project ${GOOGLE_PROJECT_ID}
            gcloud --quiet config set compute/zone ${GOOGLE_COMPUTE_ZONE}
            gcloud --quiet container clusters get-credentials ${GOOGLE_CLUSTER_NAME}
      - run:
          name: Apply deployment
          command: |
            if [ $CIRCLE_BRANCH == "master" ]
            then
              export NAMESPACE=production
              export ENV_FILE=prod.env
            else
              export NAMESPACE=staging
              export ENV_FILE=staging.env
            fi
            export BACKEND_IMAGE_TAG=$(cat /tmp/workspace/buildnum)
            source $ENV_FILE
            export $(cut -d= -f1 $ENV_FILE)
            cat kubernetes/gunicorn.yml | envsubst | kubectl apply -f - --namespace=$NAMESPACE
      - run:
          name: Setup cronjobs
          command: |
            if [ $CIRCLE_BRANCH == "master" ]
            then
              bin/run_cronjob.sh --production update_documents @daily $(cat /tmp/workspace/buildnum)
              bin/run_cronjob.sh --production crawl_ipra_portal_data @daily $(cat /tmp/workspace/buildnum)
              bin/run_cronjob.sh --production upload_document_requests @hourly $(cat /tmp/workspace/buildnum)
            else
              bin/run_cronjob.sh --staging update_documents @daily $(cat /tmp/workspace/buildnum)
              bin/run_cronjob.sh --staging crawl_ipra_portal_data @daily $(cat /tmp/workspace/buildnum)
              bin/run_cronjob.sh --staging upload_document_requests @hourly $(cat /tmp/workspace/buildnum)
            fi

  build_cpdpbot:
    machine: true
    steps:
      - checkout
      - run: echo "build-$CIRCLE_BUILD_NUM" > buildnum
      - persist_to_workspace:
          root: .
          paths:
            - buildnum
      - run:
          name: Build cpdpbot image
          command: docker build -t cpdbdev/cpdpbot:$(cat buildnum) docker/cpdpbot
      - run:
          name: Test cpdpbot image
          command: docker run -e "SETUP_LOGGING=no" --rm cpdbdev/cpdpbot:$(cat buildnum) python -m cpdpbot.test
      - run:
          name: Push cpdpbot image
          command: |
            echo $DOCKER_PASS | docker login -u $DOCKER_USER --password-stdin
            docker push cpdbdev/cpdpbot:$(cat buildnum)

  deploy_cpdpbot:
    docker:
      - image: cpdbdev/google-cloud-sdk:latest
    environment:
      PROJECT_NAME: "CPDB"
      GOOGLE_PROJECT_ID: "twitterbot-180604"
      GOOGLE_COMPUTE_ZONE: "us-central1-a"
      GOOGLE_CLUSTER_NAME: "cpdp-gke"
    steps:
      - checkout
      - attach_workspace:
          at: /tmp/workspace
      - run:
          name: Setup Google Cloud SDK
          command: |
            echo $GCLOUD_SERVICE_KEY > ${HOME}/gcloud-service-key.json
            gcloud auth activate-service-account --key-file=${HOME}/gcloud-service-key.json
            gcloud --quiet config set project ${GOOGLE_PROJECT_ID}
            gcloud --quiet config set compute/zone ${GOOGLE_COMPUTE_ZONE}
            gcloud --quiet container clusters get-credentials ${GOOGLE_CLUSTER_NAME}
      - run:
          name: Reveal secrets
          command: |
            echo $GPG_PRIVATE_KEY | base64 -d > /tmp/gpg_private.gpg
            gpg --allow-secret-key-import --import /tmp/gpg_private.gpg
            git secret reveal
      - run:
          name: Deploy cpdpbot
          command: |
            export CPDPBOT_IMAGE_TAG=$(cat /tmp/workspace/buildnum)
            source prod.env
            export $(cut -d= -f1 prod.env)
            cat kubernetes/cpdpbot.yml | envsubst | kubectl apply --namespace=production -f -


workflows:
  version: 2
  test:
    jobs:
      - test:
          filters:
            branches:
              ignore:
                - staging
                - master
  deploy_backend_staging:
    jobs:
      - test:
          filters:
            branches:
              only: staging
      - push_backend_image:
          requires:
            - test
      - django_collect_static:
          requires:
            - push_backend_image
      - django_migrate:
          requires:
            - push_backend_image
      - deploy_backend:
          requires:
            - django_migrate
            - django_collect_static
  deploy_backend_production:
    jobs:
      - test:
          filters:
            branches:
              only: master
      - push_backend_image:
          requires:
            - test
      - django_collect_static:
          requires:
            - push_backend_image
      - django_migrate:
          requires:
            - push_backend_image
      - run_cache_data:
          type: approval
          requires:
           - django_migrate
      - rebuild_index:
          requires:
            - run_cache_data
      - rebuild_search_index:
          requires:
            - run_cache_data
      - deploy_backend:
          requires:
            - rebuild_index
            - rebuild_search_index
            - django_collect_static

  deploy_cpdpbot:
    jobs:
      - build_cpdpbot:
          filters:
            branches:
              only:
                - staging
                - master
      - deploy_cpdpbot:
          filters:
            branches:
              only:
                - master
